{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083a42c-c52b-4a6a-b6c3-966f0b260ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename: output.ipynb\n",
    "# purpose: generate output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f72892-e2ae-45dd-b6cc-8448ae2fd159",
   "metadata": {},
   "source": [
    "# OHT noise, normal and outlier data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dced393-7cb5-4e2d-9c50-ffe3630527d3",
   "metadata": {},
   "source": [
    "### Outlier detection method\n",
    "- Outlier data will be detected and generated based on Moving Average and Moving Standard Deviation \n",
    "\n",
    "### Processing flow\n",
    "- Read Raw table, ohtraw from duckdb filedb, which was created in previous step, parse notebook\n",
    "- Create a Work table, work in memory duckdb with additional columns MVAVG_,MVSTD_,MVSIG_,FLAG columns.\n",
    "- Calculate Moving Average, Standard Devidation\n",
    "- Calculate Sigma value of the column data based on Moving Average and Standard Deviation\n",
    "- Calcuate FLAG column value based on Sigma value\n",
    "- Fetch the work table into work dataframe\n",
    "- Split noise and normal dataframe from work dataframe based on FLAG value\n",
    "- Create outlier dataframe based on normal dataframe\n",
    "- Update outlier dataframe by applying outlier pattern\n",
    "- Calculate Moving Average, Standard Deviation, Sigma value for outlier data\n",
    "- Prepare mix dataset with normal and outlier for ML \n",
    "- Save noise, normal, outler, mix dataframe to duckdb tables for later graphing.\n",
    "- Save noise, normal, outler, mix csvfle\n",
    "- Check csvfile size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdefb88-870e-4075-824b-53840ddb6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import time\n",
    "import pathlib\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "import humanfriendly as human\n",
    "import duckdb\n",
    "\n",
    "import ohtconf as conf\n",
    "import ohtcomm as comm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef876ffe-f89c-48dc-84dc-8157022161cc",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14141f00-7847-446e-9e64-a5be64984692",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainstart = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eaf629-aa81-4178-a17e-802bda4680d7",
   "metadata": {},
   "source": [
    "### Prepare in-memory work table base on in-file raw table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a56b9-3418-4849-9b2a-da1add197550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open in-memory db\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4f68b-90ef-4db5-a9ac-15bd316a95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create in-memory work table\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS work\"\n",
    "con.execute(query)\n",
    "\n",
    "coldef = \"\"\n",
    "for name, dtype in zip(conf.COLUMN_NAMES, conf.COLUMN_DBTYPES):\n",
    "    if coldef:\n",
    "        coldef += \", \" + name + \" \" + dtype\n",
    "    else:\n",
    "        coldef += name + \" \" + dtype\n",
    "\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    coldef += \", \" + conf.MVAVG + col + \" \" + \"FLOAT\"\n",
    "    coldef += \", \" + conf.MVSTD + col + \" \" + \"FLOAT\"\n",
    "    coldef += \", \" + conf.MVSIG + col + \" \" + \"INTEGER\"\n",
    "\n",
    "coldef += \", \" + f\"{conf.COLUMN_FLAG}  INTEGER\"\n",
    "\n",
    "query = f\"CREATE TABLE work ( {coldef} )\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98b522-6cec-4930-bc9e-1b44beab5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach in-file db, raw table was prepared in the previous step, parse\n",
    "\n",
    "con.execute(f\"ATTACH DATABASE '{conf.DBFILE}' AS filedb (READ_ONLY)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e44da7-eef3-4a61-b825-92b350893351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert into in-memory work table from in-file raw table with additional Moving Avg,Std and Flag=0\n",
    "\n",
    "coldef = \", \".join(conf.COLUMN_NAMES)\n",
    "\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    coldef += (\n",
    "        \", \"\n",
    "        + f\"AVG({col}) OVER (ORDER BY {conf.COLUMN_NAMES[0]} ROWS BETWEEN {conf.POINTS['MOVING']} PRECEDING AND CURRENT ROW) AS {conf.MVAVG}{col}\"\n",
    "    )\n",
    "    coldef += (\n",
    "        \", \"\n",
    "        + f\"STDDEV({col}) OVER (ORDER BY {conf.COLUMN_NAMES[0]} ROWS BETWEEN {conf.POINTS['MOVING']} PRECEDING AND CURRENT ROW) AS {conf.MVSTD}{col}\"\n",
    "    )\n",
    "    coldef += \", 0\"  # mvsig_\n",
    "coldef += \", 0\"  # flag\n",
    "\n",
    "query = f\"INSERT INTO work SELECT {coldef} FROM filedb.{conf.TABNAME_RAW} ORDER BY {conf.COLUMN_NAMES[0]}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7374b1-20e2-4d8d-8d54-e89299d7bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach filedb\n",
    "\n",
    "con.execute(\"DETACH DATABASE filedb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05097c7-b8cf-4bfd-9cf9-8d8f42e8aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update NULL value after window function\n",
    "query = f\"SELECT * FROM work ORDER BY {conf.COLUMN_NAMES[0]}\"\n",
    "dfwork = con.execute(query).df()\n",
    "dfwork.bfill(inplace=True)\n",
    "\n",
    "# recreate work table base one work dataframe\n",
    "con.execute(\"DROP TABLE IF EXISTS work\")\n",
    "con.execute(\"CREATE TABLE work AS SELECT * FROM dfwork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd502e22-e6cc-4196-a3af-2901490bb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Sigma value\n",
    "\n",
    "coldef = \"\"\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    setdef = textwrap.dedent(f\"\"\"{conf.MVSIG}{col} = CASE \n",
    "                  WHEN {col} >= ({col} - 1 * {conf.MVSTD}{col}) AND {col} <= ({col} + 1 * {conf.MVSTD}{col})  then 1\n",
    "                  WHEN {col} >= ({col} - 2 * {conf.MVSTD}{col}) AND {col} <= ({col} + 2 * {conf.MVSTD}{col})  then 2\n",
    "                  WHEN {col} >= ({col} - 3 * {conf.MVSTD}{col}) AND {col} <= ({col} + 3 * {conf.MVSTD}{col})  then 3\n",
    "                  WHEN {col} >= ({col} - 4 * {conf.MVSTD}{col}) AND {col} <= ({col} + 4 * {conf.MVSTD}{col})  then 4\n",
    "                  WHEN {col} >= ({col} - 5 * {conf.MVSTD}{col}) AND {col} <= ({col} + 5 * {conf.MVSTD}{col})  then 5\n",
    "                  ELSE 6\n",
    "                  END\"\"\")\n",
    "    if not coldef:\n",
    "        coldef = setdef\n",
    "    else:\n",
    "        coldef += f\", {setdef}\"\n",
    "\n",
    "query = f\"UPDATE work SET {coldef}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69bccf-9ced-46fc-8f4a-b7d4d3ec4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Flag=1 based on configured sigma value\n",
    "\n",
    "coldef = \"\"\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    if not coldef:\n",
    "        coldef = f\"{conf.MVSIG}{col} >= {conf.SIGMA_NOISE}\"\n",
    "    else:\n",
    "        coldef += f\" OR {conf.MVSIG}{col} >= {conf.SIGMA_NOISE}\"\n",
    "\n",
    "query = f\"UPDATE work SET {conf.COLUMN_FLAG}=1 WHERE {coldef}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603ddbc-416d-436d-b4ac-98da091c3554",
   "metadata": {},
   "source": [
    "### Prepare noise, normal dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d07f3-ab03-4799-a767-4eb56c23dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch table from work table based on Flag\n",
    "\n",
    "dfnoise = con.execute(f\"SELECT * FROM work WHERE {conf.COLUMN_FLAG}!=0 ORDER BY {conf.COLUMN_NAMES[0]}\").df()\n",
    "dfnorm = con.execute(f\"SELECT * FROM work WHERE {conf.COLUMN_FLAG}=0 ORDER BY {conf.COLUMN_NAMES[0]}\").df()\n",
    "\n",
    "# round float type value\n",
    "dfnoise = dfnoise.round(1)\n",
    "dfnorm = dfnorm.round(1)\n",
    "\n",
    "print(f\"row count, noise={len(dfnoise)}, normal={len(dfnorm)}, noise ratio={len(dfnoise)/(len(dfnoise)+len(dfnorm))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57493941-c8e6-48c0-9257-56ed702cf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set float display format\n",
    "pd.set_option(\"display.float_format\", \"{:.1f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b77777-3b3c-4aae-8627-ff0fe82ddf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98557e4-113c-4593-b9d3-946c59170603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnorm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bf472c-ffb7-4073-bd48-81c8640a5546",
   "metadata": {},
   "source": [
    "### Prepare outlier dataframe from normal dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60451b2-1483-4d99-9d2c-ccaab8d0fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dfoutl data in dfnorm\n",
    "\n",
    "# reset datetm value: drop any duplicates and missing.\n",
    "# keep datetm uniqueness in between normal and outlier to merge later to keep moving avg\n",
    "dfnorm[conf.COLUMN_NAMES[0]] = pd.date_range(start=\"2024-01-01\", periods=len(dfnorm), freq=\"100ms\")\n",
    "\n",
    "# take outlier candidates in splitted in datetm as moving avg is different in datetm range.\n",
    "alls = [dfnorm.iloc[i : i + conf.POINTS[\"PATTERN\"]] for i in range(0, len(dfnorm), conf.POINTS[\"PATTERN\"])]\n",
    "outls = alls[::4]\n",
    "\n",
    "# index after split by datetm ordering\n",
    "dfoutl = pd.concat(outls)\n",
    "dfoutl = dfoutl.sort_values(by=conf.COLUMN_NAMES[0])\n",
    "dfoutl = dfoutl.reset_index(drop=True)\n",
    "\n",
    "# filter dfnorm to keep only rows where datetm is not in dfoutl\n",
    "dfnorm = dfnorm[~dfnorm[conf.COLUMN_NAMES[0]].isin(dfoutl[conf.COLUMN_NAMES[0]])]\n",
    "\n",
    "# index after split by datetm ordering\n",
    "dfnorm = dfnorm.sort_values(by=conf.COLUMN_NAMES[0])\n",
    "dfnorm = dfnorm.reset_index(drop=True)\n",
    "\n",
    "print(f\"row count, outlier={len(dfoutl)}, normal={len(dfnorm)}, outlier ratio={len(dfoutl)/(len(dfoutl)+len(dfnorm))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6f556-9883-464d-8a08-e47654d4b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update outlier\n",
    "_start = time.time()\n",
    "\n",
    "dfoutl = comm.gen_outlier(dfoutl)\n",
    "\n",
    "# round float type value\n",
    "dfoutl = dfoutl.round(1)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"get_outlier elapsed time: {human.format_timespan(_elapsed)}\")\n",
    "# 8 min 17 sec, 2_031_674 rows, INPUT_MAXSIZE=400MB, include DATETM on csvfile\n",
    "# 14 min 16 sec, 3_280_186 rows, INPUT_MAXSIZE=650MB, exclude DATETM on csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c2aa7-faf9-4c84-844c-f17ac8287f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate work table base one dfoutl\n",
    "con.execute(\"DROP TABLE IF EXISTS work\")\n",
    "con.execute(\"CREATE TABLE work AS SELECT * FROM dfoutl WHERE 1=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b982a4a-e555-4cb6-ade1-66c0a8f67304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert into in-memory work table from dfoutl with calculated Moving Avg,Std and asis Flag\n",
    "\n",
    "coldef = \", \".join(conf.COLUMN_NAMES)\n",
    "\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    coldef += (\n",
    "        \", \"\n",
    "        + f\"AVG({col}) OVER (ORDER BY {conf.COLUMN_NAMES[0]} ROWS BETWEEN {conf.POINTS['MOVING']} PRECEDING AND CURRENT ROW) AS {conf.MVAVG}{col}\"\n",
    "    )\n",
    "    coldef += (\n",
    "        \", \"\n",
    "        + f\"STDDEV({col}) OVER (ORDER BY {conf.COLUMN_NAMES[0]} ROWS BETWEEN {conf.POINTS['MOVING']} PRECEDING AND CURRENT ROW) AS {conf.MVSTD}{col}\"\n",
    "    )\n",
    "    coldef += \", 0\"  # mvsig_\n",
    "coldef += \", FLAG\"  # flag\n",
    "\n",
    "query = f\"INSERT INTO work SELECT {coldef} FROM dfoutl ORDER BY {conf.COLUMN_NAMES[0]}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc97218-9c6d-4f73-88b3-ccb69db01995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update NULL value after window function\n",
    "query = f\"SELECT * FROM work ORDER BY {conf.COLUMN_NAMES[0]}\"\n",
    "dfoutl = con.execute(query).df()\n",
    "dfoutl.bfill(inplace=True)\n",
    "\n",
    "# recreate work table base one work dataframe\n",
    "con.execute(\"DROP TABLE IF EXISTS work\")\n",
    "con.execute(\"CREATE TABLE work AS SELECT * FROM dfoutl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3096c-a489-4936-82cd-b92f06b992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Sigma value\n",
    "\n",
    "coldef = \"\"\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    setdef = textwrap.dedent(f\"\"\"{conf.MVSIG}{col} = CASE \n",
    "                  WHEN {col} >= ({col} - 1 * {conf.MVSTD}{col}) AND {col} <= ({col} + 1 * {conf.MVSTD}{col})  then 1\n",
    "                  WHEN {col} >= ({col} - 2 * {conf.MVSTD}{col}) AND {col} <= ({col} + 2 * {conf.MVSTD}{col})  then 2\n",
    "                  WHEN {col} >= ({col} - 3 * {conf.MVSTD}{col}) AND {col} <= ({col} + 3 * {conf.MVSTD}{col})  then 3\n",
    "                  WHEN {col} >= ({col} - 4 * {conf.MVSTD}{col}) AND {col} <= ({col} + 4 * {conf.MVSTD}{col})  then 4\n",
    "                  WHEN {col} >= ({col} - 5 * {conf.MVSTD}{col}) AND {col} <= ({col} + 5 * {conf.MVSTD}{col})  then 5\n",
    "                  ELSE 6\n",
    "                  END\"\"\")\n",
    "    if not coldef:\n",
    "        coldef = setdef\n",
    "    else:\n",
    "        coldef += f\", {setdef}\"\n",
    "\n",
    "query = f\"UPDATE work SET {coldef}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27327d-54ea-4032-8e28-13115d5ebfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoutl = con.execute(f\"SELECT * FROM work ORDER BY {conf.COLUMN_NAMES[0]}\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd50c7-c00a-4206-a027-f9249b623fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier first pattern range data\n",
    "dfoutl.iloc[conf.POINTS[\"MOVING\"] : conf.POINTS[\"MOVING\"] + conf.POINTS[\"PATTERN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb08be-1a82-480d-ae10-025e65ce2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal the first pattern range data\n",
    "dfnorm.iloc[conf.POINTS[\"MOVING\"] : conf.POINTS[\"MOVING\"] + conf.POINTS[\"PATTERN\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6296e7a-bdb4-47c9-ab50-ab4d3ca696ce",
   "metadata": {},
   "source": [
    "### Prepare mix dataframe from normal and outlier dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3850f1d-402d-4db4-9668-b2ba856801e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare mix dataframe based on normal and outlier dataframe\n",
    "dfnorm[\"FLAG\"] = 0\n",
    "\n",
    "dfmix = pd.concat([dfnorm, dfoutl])\n",
    "dfmix = dfmix.sort_values(by=conf.COLUMN_NAMES[0])\n",
    "dfmix = dfmix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5844d9a-420c-4179-9738-32bcff12ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate work table base one dfmix\n",
    "con.execute(\"DROP TABLE IF EXISTS work\")\n",
    "con.execute(\"CREATE TABLE work AS SELECT * FROM dfmix WHERE 1=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e526e8-0304-42a9-a1fd-ffb22eb02b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert into in-memory work table from dfmix with calculated Moving Avg,Std and asis Flag value\n",
    "\n",
    "coldef = \", \".join(conf.COLUMN_NAMES)\n",
    "\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    coldef += (\n",
    "        \", \"\n",
    "        + f\"AVG({col}) OVER (ORDER BY {conf.COLUMN_NAMES[0]} ROWS BETWEEN {conf.POINTS['MOVING']} PRECEDING AND CURRENT ROW) AS {conf.MVAVG}{col}\"\n",
    "    )\n",
    "    coldef += (\n",
    "        \", \"\n",
    "        + f\"STDDEV({col}) OVER (ORDER BY {conf.COLUMN_NAMES[0]} ROWS BETWEEN {conf.POINTS['MOVING']} PRECEDING AND CURRENT ROW) AS {conf.MVSTD}{col}\"\n",
    "    )\n",
    "    coldef += \", 0\"  # mvsig_\n",
    "coldef += \", FLAG\"  # flag\n",
    "\n",
    "query = f\"INSERT INTO work SELECT {coldef} FROM dfmix ORDER BY {conf.COLUMN_NAMES[0]}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84091018-7e11-4b8a-9487-0bb0ff02d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update NULL value after window function\n",
    "query = f\"SELECT * FROM work ORDER BY {conf.COLUMN_NAMES[0]}\"\n",
    "dfmix = con.execute(query).df()\n",
    "dfmix.bfill(inplace=True)\n",
    "\n",
    "# recreate work table base one work dataframe\n",
    "con.execute(\"DROP TABLE IF EXISTS work\")\n",
    "con.execute(\"CREATE TABLE work AS SELECT * FROM dfmix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921dfba-abc5-42e1-b095-c57247a7a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Sigma value\n",
    "\n",
    "coldef = \"\"\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    setdef = textwrap.dedent(f\"\"\"{conf.MVSIG}{col} = CASE \n",
    "                  WHEN {col} >= ({col} - 1 * {conf.MVSTD}{col}) AND {col} <= ({col} + 1 * {conf.MVSTD}{col})  then 1\n",
    "                  WHEN {col} >= ({col} - 2 * {conf.MVSTD}{col}) AND {col} <= ({col} + 2 * {conf.MVSTD}{col})  then 2\n",
    "                  WHEN {col} >= ({col} - 3 * {conf.MVSTD}{col}) AND {col} <= ({col} + 3 * {conf.MVSTD}{col})  then 3\n",
    "                  WHEN {col} >= ({col} - 4 * {conf.MVSTD}{col}) AND {col} <= ({col} + 4 * {conf.MVSTD}{col})  then 4\n",
    "                  WHEN {col} >= ({col} - 5 * {conf.MVSTD}{col}) AND {col} <= ({col} + 5 * {conf.MVSTD}{col})  then 5\n",
    "                  ELSE 6\n",
    "                  END\"\"\")\n",
    "    if not coldef:\n",
    "        coldef = setdef\n",
    "    else:\n",
    "        coldef += f\", {setdef}\"\n",
    "\n",
    "query = f\"UPDATE work SET {coldef}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364491b-1606-45a0-9be8-441f2c01af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Sigma value\n",
    "\n",
    "coldef = \"\"\n",
    "for col in conf.COLUMN_GRAPH:\n",
    "    setdef = textwrap.dedent(f\"\"\"{conf.MVSIG}{col} = CASE \n",
    "                  WHEN {col} >= ({col} - 1 * {conf.MVSTD}{col}) AND {col} <= ({col} + 1 * {conf.MVSTD}{col})  then 1\n",
    "                  WHEN {col} >= ({col} - 2 * {conf.MVSTD}{col}) AND {col} <= ({col} + 2 * {conf.MVSTD}{col})  then 2\n",
    "                  WHEN {col} >= ({col} - 3 * {conf.MVSTD}{col}) AND {col} <= ({col} + 3 * {conf.MVSTD}{col})  then 3\n",
    "                  WHEN {col} >= ({col} - 4 * {conf.MVSTD}{col}) AND {col} <= ({col} + 4 * {conf.MVSTD}{col})  then 4\n",
    "                  WHEN {col} >= ({col} - 5 * {conf.MVSTD}{col}) AND {col} <= ({col} + 5 * {conf.MVSTD}{col})  then 5\n",
    "                  ELSE 6\n",
    "                  END\"\"\")\n",
    "    if not coldef:\n",
    "        coldef = setdef\n",
    "    else:\n",
    "        coldef += f\", {setdef}\"\n",
    "\n",
    "query = f\"UPDATE work SET {coldef}\"\n",
    "# print(textwrap.fill(query, width=120))\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8c2ab-aaaf-4745-8b75-ba3ae36b3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmix = con.execute(f\"SELECT * FROM work ORDER BY {conf.COLUMN_NAMES[0]}\").df()\n",
    "\n",
    "# round float type value\n",
    "dfmix = dfmix.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59597830-141f-4574-8618-3ba3695efb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "print(\n",
    "    f\"row count, mix={len(dfmix)}, normal={len(dfmix[dfmix['FLAG']==0])}, outlier={len(dfmix[dfmix['FLAG']!=0])}, outlier ratio={len(dfmix[dfmix['FLAG']!=0])/len(dfmix)}\"\n",
    ")\n",
    "dfmix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e49ab-8ea8-4bca-83a0-1c4f147b8b09",
   "metadata": {},
   "source": [
    "### Save dataframe into duckdb table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0ae20-3937-4bb6-850f-cbeb40183b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save noise\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_dftab(dfnoise, conf.TABNAME_NOISE)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save db, noise elapsed time: {human.format_timespan(_elapsed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e9b93-5fb3-469c-b5e5-225ea5d30d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save normal\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_dftab(dfnorm, conf.TABNAME_NORM)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save db, norm elapsed time: {human.format_timespan(_elapsed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735faf80-9431-425f-9e12-0115fab9a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outlier\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_dftab(dfoutl, conf.TABNAME_OUTL)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save db, outl elapsed time: {human.format_timespan(_elapsed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e125287-4b13-4890-bec1-6251dbfb5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mix\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_dftab(dfmix, conf.TABNAME_MIX)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save db, mix elapsed time: {human.format_timespan(_elapsed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbe916-3809-454e-9af3-2a24b5093a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close in-memory db\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26192ca3-2221-4ea4-a5d3-499d7b494a68",
   "metadata": {},
   "source": [
    "### Save dataframe into csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643f0d3-3182-4341-83e5-a3b43f402a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save noise\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_csvfile(dfnoise[conf.COLUMN_NAMES], conf.FILENAME_NOISE, conf.DIROUT)  # only noise\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save csvfile, noise elapsed time: {human.format_timespan(_elapsed)}\")  # no files for conf.INPUT_MAXSIZE=400 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351d757-3924-4ac0-8361-9b25803a48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save normal\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_csvfile(dfnorm[conf.COLUMN_NAMES], conf.FILENAME_NORM, conf.DIROUT)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save csvfile, norm elapsed time: {human.format_timespan(_elapsed)}\")\n",
    "#  8 min. 52 sec, 170 files, 374 MB for conf.INPUT_MAXSIZE=400 MB, exclude DATETM\n",
    "# 11 min. 49 sec, 274 files, 380 MB for conf.INPUT_MAXSIZE=650 MB, include DATETM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f4268-60f6-4300-9ce0-e53178dbab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outlier\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_csvfile(dfoutl[conf.COLUMN_NAMES], conf.FILENAME_OUTL, conf.DIROUT)\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save csvfile, outl elapsed time: {human.format_timespan(_elapsed)}\")\n",
    "# 2 min. 57 sec, 57 files 126 MB for conf.INPUT_MAXSIZE=400 MB\n",
    "# 3 min. 58 sec. 72 files 128 MB for conf.INPUT_MAXSIZE=650 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875a66f-c81c-4e15-bec2-c1dade8e79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mix\n",
    "_start = time.time()\n",
    "\n",
    "comm.save_csvfile(dfmix[conf.COLUMN_NAMES + [\"FLAG\"]], conf.FILENAME_MIX, conf.DIROUT)  # with FLAG column\n",
    "\n",
    "_elapsed = time.time() - _start\n",
    "print(f\"save csvfile, mix elapsed time: {human.format_timespan(_elapsed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036769-af44-4b68-a65d-43b11acf855e",
   "metadata": {},
   "source": [
    "### Check row count & file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74885b1a-d8e3-41d5-bbfb-b50fc01c9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display row count for check\n",
    "print(f\"row count noise={len(dfnoise)}, norm={len(dfnorm)}, outl={len(dfoutl)}, mix={len(dfmix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dba12-3d9e-4685-b74e-67bf0a4204f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display file size for check\n",
    "\n",
    "fileinfo = dict()  # count, size\n",
    "for afile in [conf.FILENAME_NOISE, conf.FILENAME_NORM, conf.FILENAME_OUTL, conf.FILENAME_MIX]:\n",
    "    basename = pathlib.Path(afile).stem\n",
    "    adir = str(pathlib.Path(conf.DIROUT) / basename)\n",
    "    files = comm.get_multifiles_indir(adir, \"*.csv\")\n",
    "    sizes = comm.get_multifiles_size(files)\n",
    "\n",
    "    fileinfo[basename] = [len(files), sum(sizes)]\n",
    "\n",
    "total_count, total_size = 0, 0\n",
    "for basename, count_size in fileinfo.items():\n",
    "    print(f\"output {basename} files={count_size[0]}, size={human.format_size(count_size[1])}\")\n",
    "    total_count = total_count + count_size[0]\n",
    "    total_size = total_size + count_size[1]\n",
    "\n",
    "print(f\"total files={total_count}, size={human.format_size(total_size)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cf135-81b8-4680-b819-d0321255ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_elapsed = time.time() - mainstart\n",
    "print(f\"main elapsed time: {human.format_timespan(_elapsed)}\")\n",
    "# 3 min.  for conf.INPUT_MAXSIZE=400MB, when include DATETM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6407f8-6769-41df-9268-559558321b38",
   "metadata": {},
   "source": [
    "## eof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
